from langgraph.types import Command
from langchain_core.messages import HumanMessage
from ai_agent.config import State


def main_loop(graph,cleanup_function=None):
    # ä¸»å¾ªç¯
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. å¼€å§‹å¯¹è¯")
        print("2. æ¸…ç†å¯¹è¯æ•°æ®")
        print("3. è§¦å‘å¯¹è¯æ€»ç»“")
        print("4. é€€å‡º")
    
        main_choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
    
        if main_choice == "1":
            user_id = input("è¯·è¾“å…¥ç”¨æˆ·ID: ")
            user_rollback_choice=input("æ˜¯å¦å›æ¡£ï¼Ÿ1/2")
            if user_rollback_choice =="1":
                # ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„user_idæ¥è·å–æ£€æŸ¥ç‚¹å†å²
                user_config = {"configurable": {"thread_id": user_id}}
                states = list(graph.get_state_history(user_config))
                print("\nå¯ç”¨çš„å›æ¡£ç‚¹:")
                for index, state in enumerate(states):
                    print(f"[{index}] {state.next}")
                    print(f"    æ£€æŸ¥ç‚¹ID: {state.config['configurable']['checkpoint_id']}")
                
                    # æ˜¾ç¤ºæœ€åä¸€æ¡æ¶ˆæ¯å†…å®¹
                    messages = state.values.get("messages", [])
                    if messages:
                        last_message = messages[-1]
                        message_type = last_message.type if hasattr(last_message, 'type') else 'unknown'
                        content = last_message.content if hasattr(last_message, 'content') else str(last_message)
                    
                        # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ˜¾ç¤ºå·¥å…·ä¿¡æ¯
                        if message_type == 'ai' and hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                            tool_names = [tc.get('name', 'unknown') for tc in last_message.tool_calls]
                            content = f"å·¥å…·è°ƒç”¨: {', '.join(tool_names)}"
                    
                        print(f"    æœ€åæ¶ˆæ¯: [{message_type}] {content[:80]}{'...' if len(content) > 80 else ''}")
                    else:
                        print("    æœ€åæ¶ˆæ¯: [æ— æ¶ˆæ¯]")
                    print()
                # é€‰æ‹©å›æ¡£ç‚¹
                user_rollback_id=int(input("é€‰æ‹©å›æ¡£ç‚¹å¼€å§‹åˆ›å»ºåˆ†æ”¯"))
                # æ‰“å°è¯¥å­˜æ¡£ç‚¹ä¿¡æ¯
                selected_state = states[user_rollback_id]
                print(selected_state.next)
                print(selected_state.values)
                # åªå…è®¸ä»étoolsæ£€æŸ¥ç‚¹å›æ¡£
                # å¦‚æœæ²¡æœ‰ä¸­æ–­æˆ–å·¥å…·è°ƒç”¨ï¼Œç»§ç»­æ­£å¸¸å¯¹è¯
            
                user_rollback_update=input("è¯·è¾“å…¥è¦†ç›–ä¿¡æ¯ï¼š")
                # æ›´æ–°çŠ¶æ€ï¼šè·å–æ•´ä¸ªæ¶ˆæ¯åˆ—è¡¨ï¼Œå»æ‰æœ€åä¸€æ¡ç”¨æˆ·ä¿¡æ¯ï¼Œæ·»åŠ æ–°çš„ç”¨æˆ·æ¶ˆæ¯
                current_messages = selected_state.values.get("messages", [])
            
                # å¦‚æœæ¶ˆæ¯åˆ—è¡¨ä¸ºç©ºï¼Œç›´æ¥æ·»åŠ æ–°æ¶ˆæ¯
                if not current_messages:
                    new_messages = [HumanMessage(content=user_rollback_update)]
                else:
                    # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯ç”¨æˆ·æ¶ˆæ¯
                    last_message = current_messages[-1]
                    if hasattr(last_message, 'type') and last_message.type == 'human':
                        # å¦‚æœæœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œæ›¿æ¢å®ƒ
                        new_messages = current_messages[:-1] + [HumanMessage(content=user_rollback_update)]
                    else:
                        # å¦‚æœæœ€åä¸€æ¡ä¸æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œç›´æ¥æ·»åŠ æ–°æ¶ˆæ¯
                        new_messages = current_messages + [HumanMessage(content=user_rollback_update)]
            
                # ç”¨æ•´ä¸ªæ–°çŠ¶æ€æ›¿æ¢åŸæœ¬çš„æ—§çŠ¶æ€
                new_config = graph.update_state(selected_state.config, values={"messages": new_messages})
                print(f"æ›´æ–°æˆåŠŸ{new_config}")
                # è§¦å‘å›å¤

                # ä½¿ç”¨æµå¼ä¼ è¾“å¤„ç†å›æ¡£å“åº”
                print("å›æ¡£å“åº”:")
                for chunk in graph.stream(None, new_config, stream_mode="updates"):
                    print(chunk)
                rollback_response = graph.get_state(new_config)
                print(f"å›æ¡£å®Œæˆï¼Œå½“å‰çŠ¶æ€: {rollback_response}")
            else:
                print("ä»ä¸Šæ¬¡é€€å‡ºç‚¹ï¼Œç»§ç»­å¯¹è¯")
                # åŠ¨æ€è®¾ç½®thread_idï¼Œæ”¯æŒå¤šç”¨æˆ·
                config = {"configurable": {"thread_id": user_id}}
            
                # è·å–å½“å‰çŠ¶æ€ä»¥ä¿æŒå¯¹è¯å†å²
                current_state = graph.get_state(config)
                current_messages = current_state.values.get("messages", [])
                
                # è¯¢é—®æ˜¯å¦åˆ é™¤æ¶ˆæ¯
                delete_choice = input("æ˜¯å¦åˆ é™¤æ¶ˆæ¯åå†å¯¹è¯ï¼Ÿ(1=æ˜¯, 2=å¦): ").strip()
                
                if delete_choice == "1":
                    # æ˜¾ç¤ºå½“å‰æ¶ˆæ¯åˆ—è¡¨
                    print("\nå½“å‰æ¶ˆæ¯å†å²:")
                    for i, msg in enumerate(current_messages):
                        msg_type = msg.type if hasattr(msg, 'type') else 'unknown'
                        msg_content = msg.content if hasattr(msg, 'content') else str(msg)
                        print(f"  [{i}] ID: {msg.id} | {msg_type}: {msg_content[:50]}{'...' if len(msg_content) > 50 else ''}")
                    
                    # è¯¢é—®è¦åˆ é™¤çš„æ¶ˆæ¯ID
                    delete_ids_input = input("è¯·è¾“å…¥è¦åˆ é™¤çš„æ¶ˆæ¯IDï¼ˆå¤šä¸ªIDç”¨é€—å·åˆ†éš”ï¼Œæˆ–è¾“å…¥'all'åˆ é™¤æ‰€æœ‰ï¼‰: ").strip()
                    
                    if delete_ids_input.lower() == 'all':
                        # ä½¿ç”¨è‡ªå®šä¹‰åˆ é™¤æŒ‡ä»¤åˆ é™¤æ‰€æœ‰æ¶ˆæ¯
                        delete_instruction = HumanMessage(content="/delete all")
                        updated_messages = current_messages + [delete_instruction]
                        
                        # è°ƒç”¨å›¾ï¼Œæ¡ä»¶è¾¹ä¼šè‡ªåŠ¨è·¯ç”±åˆ°è‡ªå®šä¹‰åˆ é™¤èŠ‚ç‚¹
                        result = graph.invoke(
                            {"messages": updated_messages},
                            config
                        )
                        print("å·²åˆ é™¤æ‰€æœ‰æ¶ˆæ¯")
                        current_messages = result["messages"]
                    else:
                        # åˆ é™¤æŒ‡å®šæ¶ˆæ¯
                        delete_ids = [id.strip() for id in delete_ids_input.split(',')]
                        
                        # ä¸ºæ¯ä¸ªè¦åˆ é™¤çš„æ¶ˆæ¯åˆ›å»ºåˆ é™¤æŒ‡ä»¤
                        for msg_id in delete_ids:
                            try:
                                index = int(msg_id)
                                if 0 <= index < len(current_messages):
                                    # ä½¿ç”¨è‡ªå®šä¹‰åˆ é™¤æŒ‡ä»¤åˆ é™¤ç‰¹å®šç´¢å¼•çš„æ¶ˆæ¯
                                    delete_instruction = HumanMessage(content=f"/delete index {index}")
                                    updated_messages = current_messages + [delete_instruction]
                                    
                                    # è°ƒç”¨å›¾ï¼Œæ¡ä»¶è¾¹ä¼šè‡ªåŠ¨è·¯ç”±åˆ°è‡ªå®šä¹‰åˆ é™¤èŠ‚ç‚¹
                                    result = graph.invoke(
                                        {"messages": updated_messages},
                                        config
                                    )
                                    current_messages = result["messages"]
                                    print(f"å·²åˆ é™¤ç´¢å¼• {index} çš„æ¶ˆæ¯")
                                else:
                                    print(f"æ— æ•ˆçš„æ¶ˆæ¯ç´¢å¼•: {index}")
                            except ValueError:
                                print(f"æ— æ•ˆçš„æ¶ˆæ¯IDæ ¼å¼: {msg_id}")
                        
                        continue
                
                # è¿›è¡Œå¯¹è¯
                user_input = input("è¯·è¾“å…¥å¯¹è¯æ–‡æœ¬: ")
                # å°†æ–°æ¶ˆæ¯æ·»åŠ åˆ°ç°æœ‰æ¶ˆæ¯åˆ—è¡¨ä¸­
                updated_messages = current_messages + [HumanMessage(content=user_input)]
                input_state = State(messages=updated_messages)
            
                # ä½¿ç”¨æµå¼ä¼ è¾“å¤„ç†å¯¹è¯å“åº”
                print("AIå“åº”:")
                for message_chunk, metadata in graph.stream(input_state, config, stream_mode="messages"):
                    if message_chunk.content:
                        print(message_chunk.content, end="", flush=True)
                print()  # æ·»åŠ æ¢è¡Œ
                result = graph.get_state(config)
                print(f"å¯¹è¯å®Œæˆï¼Œå½“å‰çŠ¶æ€: {result}")
        
                # å¤„ç†å·¥å…·ä¸­æ–­å¾ªç¯
                while hasattr(result, 'interrupts') and result.interrupts:
                    print(f"å·¥å…·ä¸­æ–­: {result}")
                    for interrupt in result.interrupts:
                        print(f"ä¸­æ–­ä¿¡æ¯: {interrupt.value}")
                    
                    choice_action = input("è¯·é€‰æ‹©æ“ä½œ (1=æ¢å¤, 2=å–æ¶ˆ): ").strip()
                    choice_data = input("è¯·è¾“å…¥é™„åŠ ä¿¡æ¯: ").strip()
                    
                    human_response = Command(
                        resume= {
                            "choice_action": choice_action,
                            "choice_data": choice_data
                        }
                    )
                    # ä½¿ç”¨æµå¼ä¼ è¾“å¤„ç†ä¸­æ–­å“åº”
                    print("ä¸­æ–­å“åº”:")
                    for chunk in graph.stream(human_response, config, stream_mode="updates"):
                        print(chunk)
                    result = graph.get_state(config)
                    print(f"å·¥å…·ä¸­æ–­å¤„ç†å®Œæˆï¼Œå½“å‰çŠ¶æ€: {result}")
    
        elif main_choice == "2":
            if cleanup_function:
                cleanup_function()
            else:
                print("æ¸…ç†åŠŸèƒ½ä¸å¯ç”¨")
    
        elif main_choice == "3":
            # è§¦å‘å¯¹è¯æ€»ç»“
            user_id = input("è¯·è¾“å…¥ç”¨æˆ·ID: ")
            config = {"configurable": {"thread_id": user_id}}
            
            # è·å–å½“å‰çŠ¶æ€
            current_state = graph.get_state(config)
            current_messages = current_state.values.get("messages", [])
            
            if not current_messages:
                print("æ²¡æœ‰å¯¹è¯å†å²å¯æ€»ç»“")
                continue
            
            # ä½¿ç”¨æ€»ç»“æŒ‡ä»¤è§¦å‘æ€»ç»“
            summarize_instruction = HumanMessage(content="/summarize")
            updated_messages = current_messages + [summarize_instruction]
            input_state = State(messages=updated_messages)
            print(input_state)
            print("æ­£åœ¨ç”Ÿæˆå¯¹è¯æ€»ç»“...")
            # ä½¿ç”¨æµå¼ä¼ è¾“å¤„ç†æ€»ç»“å“åº”
            print("æ€»ç»“ç”Ÿæˆä¸­...")
            for chunk in graph.stream(input_state, config, stream_mode="updates"):
                print(chunk)
            result = graph.get_state(config)
            
            # æ˜¾ç¤ºæ›´æ–°åçš„æ€»ç»“
            updated_state = graph.get_state(config)
            updated_messages_after = updated_state.values.get("messages", [])
            
            # ä»æœ€åä¸€æ¡æ¶ˆæ¯ä¸­è·å–æ€»ç»“å†…å®¹
            updated_summary = ""
            if updated_messages_after:
                last_message = updated_messages_after[-1]
                if hasattr(last_message, 'content'):
                    updated_summary = last_message.content
            
            if updated_summary:
                print(f"\nğŸ“ æ›´æ–°åçš„å¯¹è¯æ€»ç»“: {updated_summary}")
            else:
                print("æ€»ç»“ç”Ÿæˆå¤±è´¥")
        
        elif main_choice == "4":
            print("ç¨‹åºé€€å‡º")
            break

        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")