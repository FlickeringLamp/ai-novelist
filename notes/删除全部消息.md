# 问题描述：
当使用await graph.aupdate_state(config, {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]})来删除全部消息时，会有如下报错
目前排除State不合规
class State(MessagesState):
    """包含消息的状态,不包括系统提示词"""
    documents: list[str]

暂时不做处理，直接使用原本的删除api，删掉整个对话历史（或者前端统计所有消息的id后，传给后端即可）
怎么说呢，感觉对话历史这块，langchain/langgraph没有现成的预购建组件可用，还是得用sqlite底层的api

```py
@router.post("/messages/operation", summary="操作历史消息", response_model=Dict[str, Any])
async def operate_messages(request: OperateMessagesRequest):
    """
    对历史消息进行删除操作
    
    - **thread_id**: 会话ID
    - **target_ids**: 目标消息ID列表（可选，未传则删除全部）
    """
    thread_id = request.thread_id
    target_ids = request.target_ids
    
    # 使用装饰器创建图操作函数
    @with_graph_builder
    async def process_operate_messages(graph):
        """处理操作历史消息"""
        config: RunnableConfig = {"configurable": {"thread_id": thread_id}}
        
        if target_ids is None:
            # 删除所有消息
            await graph.aupdate_state(config, {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]})
            return {"message": "已删除所有消息"}
        else:
            # 删除指定ID的消息（支持多个）
            remove_messages = [RemoveMessage(id=target_id) for target_id in target_ids]
            await graph.aupdate_state(config, {"messages": remove_messages})
            return {"message": f"已删除消息ID: {', '.join(target_ids)}"}
    
    # 使用async for遍历生成器并获取结果
    result = None
    async for item in process_operate_messages():
        result = item
    return result
```



ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "E:\ai-novelist\backend_env\Lib\site-packages\uvicorn\protocols\http\httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.scope, self.receive, self.send
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\ai-novelist\backend_env\Lib\site-packages\uvicorn\middleware\proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\ai-novelist\backend_env\Lib\site-packages\fastapi\applications.py", line 1134, in __call__
    await super().__call__(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\applications.py", line 107, in __call__
    await self.middleware_stack(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\middleware\errors.py", line 186, in __call__
    raise exc
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\middleware\errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\middleware\cors.py", line 93, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\middleware\cors.py", line 144, in simple_response
    await self.app(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\middleware\exceptions.py", line 63, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "E:\ai-novelist\backend_env\Lib\site-packages\fastapi\middleware\asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\routing.py", line 716, in __call__
    await self.middleware_stack(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\routing.py", line 736, in app
    await route.handle(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\routing.py", line 290, in handle
    await self.app(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\fastapi\routing.py", line 125, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "E:\ai-novelist\backend_env\Lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "E:\ai-novelist\backend_env\Lib\site-packages\fastapi\routing.py", line 111, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "E:\ai-novelist\backend_env\Lib\site-packages\fastapi\routing.py", line 391, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "E:\ai-novelist\backend_env\Lib\site-packages\fastapi\routing.py", line 290, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\ai-novelist\backend\api\history_api.py", line 205, in operate_messages
    async for item in process_operate_messages():
        result = item
  File "E:\ai-novelist\backend\ai_agent\core\graph_builder.py", line 255, in wrapper
    result = await result
             ^^^^^^^^^^^^
  File "E:\ai-novelist\backend\api\history_api.py", line 195, in process_operate_messages
    await graph.aupdate_state(config, {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]})
  File "E:\ai-novelist\backend_env\Lib\site-packages\langgraph\pregel\main.py", line 2333, in aupdate_state
    return await self.abulk_update_state(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config, [[StateUpdate(values, as_node, task_id)]]
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\ai-novelist\backend_env\Lib\site-packages\langgraph\pregel\main.py", line 2306, in abulk_update_state
    current_config = await aperform_superstep(current_config, superstep)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\ai-novelist\backend_env\Lib\site-packages\langgraph\pregel\main.py", line 2239, in aperform_superstep
    await run.ainvoke(
    ...<25 lines>...
    )
  File "E:\ai-novelist\backend_env\Lib\site-packages\langchain_core\runnables\base.py", line 3191, in ainvoke
    input_ = await coro_with_context(part(), context, create_task=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\ai-novelist\backend_env\Lib\site-packages\langgraph\_internal\_runnable.py", line 473, in ainvoke
    ret = await self.afunc(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\ai-novelist\backend_env\Lib\site-packages\langgraph\graph\_branch.py", line 189, in _aroute
    result = await self.path.ainvoke(value, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\ai-novelist\backend_env\Lib\site-packages\langgraph\_internal\_runnable.py", line 464, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\ai-novelist\backend_env\Lib\site-packages\langchain_core\runnables\config.py", line 610, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
    )
    ^
  File "C:\Users\denghuo\AppData\Local\Programs\Python\Python313\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "E:\ai-novelist\backend_env\Lib\site-packages\langchain_core\runnables\config.py", line 601, in wrapper
    return func(*args, **kwargs)
  File "E:\ai-novelist\backend_env\Lib\site-packages\langgraph\prebuilt\tool_node.py", line 1524, in tools_condition
    raise ValueError(msg)
ValueError: No messages found in input state to tool_edge: {'messages': []}